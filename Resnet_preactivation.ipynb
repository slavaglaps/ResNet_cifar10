{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "import tensorflow\n",
    "\n",
    "%env KERAS_BACKEND=tensorflow\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import keras\n",
    "from keras.layers import Input\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import ZeroPadding2D\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications.imagenet_utils import _obtain_input_shape\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def identity_block_preactive(input_tensor, kernel_size,filters):\n",
    "\n",
    "    filters1, filters2 = filters\n",
    "    \n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "  \n",
    "    x = BatchNormalization(axis=bn_axis)(input_tensor)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(filters1, (3, 3),padding='same',\n",
    "               kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(0.0001))(x)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, (3,3),\n",
    "               padding='same',\n",
    "               kernel_initializer=\"he_normal\",\n",
    "               kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "    x = layers.add([x, input_tensor])\n",
    "\n",
    "    return x\n",
    "\n",
    "def conv_block_preactive(input_tensor, kernel_size, filters, strides=(2, 2)):\n",
    "\n",
    "    filters1, filters2 = filters\n",
    "    \n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "        \n",
    "    x_act = Activation('relu')(input_tensor)    \n",
    "    x = Conv2D(filters1, (3, 3), strides=strides,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          padding=\"same\",\n",
    "                          kernel_regularizer=l2(0.0001))(x_act)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters2, (3,3), padding='same',\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(x)\n",
    "\n",
    "\n",
    "    shortcut = Conv2D(filters2, (1, 1), strides=strides,\n",
    "                          kernel_initializer=\"he_normal\",\n",
    "                          kernel_regularizer=l2(0.0001))(x_act)\n",
    "    \n",
    "    x = layers.add([x, shortcut])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet_wide(input_tensor=None, input_shape=None,\n",
    "                pooling=None):\n",
    "    # Determine proper input shape\n",
    "    input_shape = (32,32,3)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "        \n",
    "    block_shape = K.int_shape(img_input)\n",
    "    print(img_input)\n",
    "    x = Conv2D(16, (3, 3), strides=(1, 1),padding=\"same\")(img_input)\n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    \n",
    "    \n",
    "    block_shape = K.int_shape(x)\n",
    "    print(block_shape)\n",
    "    \n",
    "    x = conv_block_preactive(x, 3, [32,32], strides=(1, 1))\n",
    "    x = identity_block_preactive(x, 3, [32,32])\n",
    "    x = identity_block_preactive(x, 3, [32,32]) \n",
    "    x = identity_block_preactive(x, 3, [32,32]) \n",
    "    x = identity_block_preactive(x, 3, [32,32]) \n",
    "    x = identity_block_preactive(x, 3, [32,32]) \n",
    "    \n",
    "    block_shape = K.int_shape(x)\n",
    "    print(block_shape)\n",
    "  \n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    \n",
    "    x = conv_block_preactive(x, 3, [64,64])\n",
    "    x = identity_block_preactive(x, 3, [64,64])\n",
    "    x = identity_block_preactive(x, 3, [64,64])\n",
    "    x = identity_block_preactive(x, 3, [64,64])\n",
    "    x = identity_block_preactive(x, 3, [64,64])\n",
    "    x = identity_block_preactive(x, 3, [64,64])\n",
    "    block_shape = K.int_shape(x)\n",
    "    print(block_shape)\n",
    "    \n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    \n",
    "    x = conv_block_preactive(x, 3, [128,128])\n",
    "    x = identity_block_preactive(x, 3, [128,128])\n",
    "    x = identity_block_preactive(x, 3, [128,128])\n",
    "    x = identity_block_preactive(x, 3, [128,128])\n",
    "    x = identity_block_preactive(x, 3, [128,128])\n",
    "    x = identity_block_preactive(x, 3, [128,128])\n",
    "    \n",
    "    block_shape = K.int_shape(x)\n",
    "    print(block_shape)\n",
    "    \n",
    "    x = BatchNormalization(axis=bn_axis)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    block_shape = K.int_shape(x)\n",
    "    x = AveragePooling2D(pool_size=(8, 8),strides=(1, 1))(x) \n",
    "    x = Flatten()(x)\n",
    "    x  = Dense(10, activation='softmax', name='fc1000')(x)\n",
    "    \n",
    "    block_shape = K.int_shape(x)\n",
    "    print(block_shape)\n",
    "\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='resnet50')\n",
    "   \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_17:0\", shape=(?, 32, 32, 3), dtype=float32)\n",
      "(None, 32, 32, 16)\n",
      "(None, 32, 32, 32)\n",
      "(None, 16, 16, 64)\n",
      "(None, 8, 8, 128)\n",
      "(None, 10)\n"
     ]
    }
   ],
   "source": [
    "model = ResNet_wide()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255 \n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "sgd = SGD(lr=0.1, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=sgd, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=True,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "train_datagen.fit(x_train, augment=True, rounds=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "batch_size = 128\n",
    "nb_classes = 10\n",
    "nb_epoch = 200\n",
    "\n",
    "\n",
    "lr_schedule = [40, 80, 160] # epoch_step\n",
    "def schedule(epoch_idx):\n",
    "    if (epoch_idx + 1) < lr_schedule[0]:\n",
    "        return 0.1\n",
    "    elif (epoch_idx + 1) < lr_schedule[1]:\n",
    "        return 0.01 # lr_decay_ratio = 0.2\n",
    "    elif (epoch_idx + 1) < lr_schedule[2]:\n",
    "        return 0.001\n",
    "    return 0.0001\n",
    "\n",
    "callbacks = [ LearningRateScheduler(schedule=schedule)]\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=nb_epoch,\n",
    "                    callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
